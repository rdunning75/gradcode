{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e249fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600c946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "traning = r'D:\\CS_Course_Material\\Graduate_Program\\workspace\\DATA\\2015-2020\\firemask\\train'\n",
    "validation = r'D:\\CS_Course_Material\\Graduate_Program\\workspace\\DATA\\2015-2020\\firemask\\validate'\n",
    "test = r'D:\\CS_Course_Material\\Graduate_Program\\workspace\\DATA\\2015-2020\\firemask\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed2da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers, preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92166f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "175925ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "rescale=1. /255,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip = True)\n",
    "\n",
    "validate_datagen = ImageDataGenerator(\n",
    "rescale=1. /255,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip = True)\n",
    "\n",
    "test_datagen  = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df03f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_samples = 34\n",
    "val_samples = 8\n",
    "img_width =  100 \n",
    "img_height = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2077d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 318 images belonging to 2 classes.\n",
      "Found 53 images belonging to 2 classes.\n",
      "Found 10 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    traning,\n",
    "    color_mode ='grayscale',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode ='binary'\n",
    ")\n",
    "\n",
    "validate_generator = validate_datagen.flow_from_directory(\n",
    "    validation,\n",
    "    color_mode ='grayscale',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode ='binary'\n",
    ")\n",
    "\n",
    "test_generator  = test_datagen.flow_from_directory(\n",
    "    test,\n",
    "    target_size=(img_width, img_height),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=1,\n",
    "    class_mode=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20083d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (267, 100, 1)\n",
    "\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "seq = Sequential()\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   input_shape=(None, 100,1, 1),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "               activation='sigmoid',\n",
    "               padding='same', data_format='channels_last'))\n",
    "seq.add(Flatten())\n",
    "seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62117034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d (ConvLSTM2D)    (None, None, 100, 1, 40)  59200     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, 100, 1, 40)  160      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, None, 100, 1, 40)  115360    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, None, 100, 1, 40)  160      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv_lstm2d_2 (ConvLSTM2D)  (None, None, 100, 1, 40)  115360    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, None, 100, 1, 40)  160      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv_lstm2d_3 (ConvLSTM2D)  (None, None, 100, 1, 40)  115360    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, None, 100, 1, 40)  160      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d (Conv3D)             (None, None, 100, 1, 1)   1081      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,001\n",
      "Trainable params: 406,681\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "222da6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.compile(loss='binary_crossentropy',\n",
    "optimizer='rmsprop',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b68cef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "53\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.n)\n",
    "print(validate_generator.n)\n",
    "print(train_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dea0a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "3\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 143s 7s/step - loss: 0.1312 - accuracy: 0.0795\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 149s 8s/step - loss: 0.0325 - accuracy: 0.2483\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 173s 9s/step - loss: 0.0190 - accuracy: 0.3477\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 174s 9s/step - loss: 0.0032 - accuracy: 0.5033\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 188s 10s/step - loss: 0.0330 - accuracy: 0.2185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b1de0ed90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validate_generator.n//validate_generator.batch_size\n",
    "print(STEP_SIZE_TRAIN)\n",
    "print(STEP_SIZE_VALID)\n",
    "# seq.fit_generator(generator=train_generator,\n",
    "#                     steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "#                     validation_data=validate_generator,-\n",
    "#                     validation_steps=STEP_SIZE_VALID,\n",
    "#                     epochs=10 )\n",
    "seq.fit(train_generator,\n",
    "        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "        validation_steps=STEP_SIZE_VALID,\n",
    "        epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11d8fd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53 images belonging to 2 classes.\n",
      "53/53 [==============================] - 6s 105ms/step - loss: 0.3221 - accuracy: 0.7547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3220953047275543, 0.7547169923782349]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_generator = validate_datagen.flow_from_directory(\n",
    "    validation,\n",
    "    color_mode ='grayscale',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=1,\n",
    "    class_mode ='binary'\n",
    ")\n",
    "\n",
    "seq.evaluate(validate_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aecbcd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53 images belonging to 2 classes.\n",
      "53/53 [==============================] - 7s 133ms/step - loss: 0.4107 - accuracy: 0.7547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41067516803741455, 0.7547169923782349]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_generator = validate_datagen.flow_from_directory(\n",
    "    validation,\n",
    "    color_mode ='grayscale',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=1,\n",
    "    class_mode ='binary'\n",
    ")\n",
    "\n",
    "seq.evaluate(validate_generator)\n",
    "# seq.evaluate(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e0e8227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryand\\AppData\\Local\\Temp/ipykernel_25524/3463824732.py:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred=seq.predict_generator(test_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 171ms/step\n"
     ]
    }
   ],
   "source": [
    "# STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "# test_generator.reset()\n",
    "# pred=seq.predict_generator(test_generator,\n",
    "# steps=STEP_SIZE_TEST,\n",
    "# verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict next \n",
    "\n",
    "# select a random value for validation\n",
    "randFireMap = validate_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d6e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Durration\n",
    "Fire\n",
    "nvi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
